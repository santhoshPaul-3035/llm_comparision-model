import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

import os
import numpy as np
from torchvision.datasets import MNIST
from torchvision.utils import save_image, make_grid

# Set hyperparameters
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

num_epochs = 20
batch_size = 128
learning_rate = 0.001
img_dir = './ae_images'
os.makedirs(img_dir, exist_ok=True)

# MNIST dataset preparation
transform = transforms.Compose([
    transforms.ToTensor(),
    # transforms.Normalize((0.5,), (0.5,)) # No normalization for simple AE
])

train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)
test_dataset = MNIST(root='./data', train=False, transform=transform, download=True)

train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)

class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        # Encoder
        self.encoder = nn.Sequential(
            nn.Linear(28 * 28, 128),
            nn.ReLU(True),
            nn.Linear(128, 64),
            nn.ReLU(True),
            nn.Linear(64, 12),
            nn.ReLU(True),
            nn.Linear(12, 3)  # Bottleneck layer (latent space)
        )
        # Decoder
        self.decoder = nn.Sequential(
            nn.Linear(3, 12),
            nn.ReLU(True),
            nn.Linear(12, 64),
            nn.ReLU(True),
            nn.Linear(64, 128),
            nn.ReLU(True),
            nn.Linear(128, 28 * 28),
            nn.Sigmoid()  # Use Sigmoid to output values between 0 and 1
        )

    def forward(self, x):
        x = x.view(-1, 28 * 28)  # Flatten the image
        x_encoded = self.encoder(x)
        x_decoded = self.decoder(x_encoded)
        x_decoded = x_decoded.view(-1, 1, 28, 28) # Reshape back to image
        return x_decoded

model = Autoencoder().to(device)
criterion = nn.MSELoss() # Mean Squared Error Loss
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Training loop
print("Starting Training...")
for epoch in range(num_epochs):
    for data in train_loader:
        img, _ = data
        img = img.to(device)
        
        # Flatten image for input, but target is the original image
        # The model handles flattening internally
        # img_flat = img.view(img.size(0), -1)
        
        # ===================forward=====================
        output = model(img)
        loss = criterion(output, img) # Compare reconstructed image to original
        
        # ===================backward====================
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    
    # ===================log========================
    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

    if epoch % 5 == 0 or epoch == num_epochs - 1:
        # Save reconstructed images from the last batch
        with torch.no_grad():
            # Get a batch from the test loader
            test_iter = iter(test_loader)
            test_data = next(test_iter)
            test_img, _ = test_data
            test_img = test_img.to(device)

            reconstructed = model(test_img)
            
            # Combine original and reconstructed images
            combined_imgs = torch.cat([test_img.cpu(), reconstructed.cpu()])
            grid = make_grid(combined_imgs, nrow=batch_size, padding=2, normalize=True)
            
            save_path = os.path.join(img_dir, f'reconstruction_epoch_{epoch+1}.png')
            save_image(grid, save_path)
            print(f"Saved reconstructed images to {save_path}")

print("Training finished.")

# Function to test the autoencoder
def test_autoencoder(model, test_loader, device):
    model.eval() # Set model to evaluation mode
    
    with torch.no_grad():
        # Get a batch of test images
        dataiter = iter(test_loader)
        images, labels = next(dataiter)
        images = images.to(device)

        # Reconstruct images
        outputs = model(images)

        # Move images to CPU for plotting
        images = images.cpu()
        outputs = outputs.cpu()

        # Plot the first 10 images and their reconstructions
        fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))
        
        print("Top row: Original Images")
        print("Bottom row: Reconstructed Images")
        
        for i in range(10):
            # Display original
            ax = axes[0, i]
            ax.imshow(images[i].squeeze(), cmap='gray')
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
            if i == 0:
                ax.set_ylabel("Original", rotation=90, size='large')

            # Display reconstruction
            ax = axes[1, i]
            ax.imshow(outputs[i].squeeze(), cmap='gray')
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
            if i == 0:
                ax.set_ylabel("Reconstructed", rotation=90, size='large')
                
        plt.show()

test_autoencoder(model, test_loader, device)