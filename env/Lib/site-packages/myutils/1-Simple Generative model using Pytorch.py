# Install & Import
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Hyperparameters
latent_dim = 64    # Random noise size
hidden_dim = 256
image_dim = 28 * 28  # MNIST images flattened
batch_size = 128
epochs = 10
lr = 0.0002

# Load MNIST Dataset
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Lambda(lambda x: x.view(-1))  # Flatten 28x28 â†’ 784
])

train_dataset = datasets.MNIST(root="./data", train=True, transform=transform, download=True)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

# Define a Simple Generator Network
# This network takes random noise z and outputs a fake image.
class Generator(nn.Module):
    def __init__(self, latent_dim, hidden_dim, image_dim):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, image_dim),
            nn.Sigmoid()  # Output in [0,1] for images
        )

    def forward(self, z):
        return self.model(z)

# Setup Model, Loss, Optimizer
# Naive training: make the generator output similar to real images.
generator = Generator(latent_dim, hidden_dim, image_dim).to(device)
optimizer = optim.Adam(generator.parameters(), lr=lr)
criterion = nn.MSELoss()  # Simple pixel-level loss

# Training Loop
for epoch in range(epochs):
    for real_images, _ in train_loader:
        real_images = real_images.to(device)

        # Sample random noise
        z = torch.randn(real_images.size(0), latent_dim).to(device)

        # Generate fake images
        fake_images = generator(z)

        # Loss: make fake_images look like real_images (naive)
        loss = criterion(fake_images, real_images)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}")

# Generate New Images
# After training:
# Sample random noise
z = torch.randn(16, latent_dim).to(device)
generated = generator(z).cpu().detach().view(-1, 28, 28)

# Show 16 generated samples
plt.figure(figsize=(4,4))
for i in range(16):
    plt.subplot(4,4,i+1)
    plt.imshow(generated[i], cmap="grey")
    plt.axis("off")
plt.show()
